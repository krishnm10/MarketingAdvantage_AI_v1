# ==========================================================
# üöÄ intelligent_excel_ingest.py ‚Äî Enterprise-Grade Smart Excel/CSV Ingestion (v3.0)
# ==========================================================
"""
Reads Excel/CSV files row by row, sends each row to DeepSeek (Ollama)
via llm_classifier.py for intelligent classification, and stores the
results into Postgres (taxonomy + business + content + links) and ChromaDB.

‚úÖ Auto-detects and classifies business, strategy, KPI, or trends
‚úÖ Dynamically grows taxonomy hierarchy
‚úÖ Deduplicates and fingerprints content
‚úÖ Supports multi-format .xlsx and .csv ingestion
‚úÖ Logs all reasoning and classification traces

Author: MarketingAdvantage‚Ñ¢ AI Core Team
Version: 3.0
"""

import os
import json
import pandas as pd
import logging
from datetime import datetime

from api.connection import get_db_connection
from api.db import models
from api.services.llm_classifier import classify_text_with_llm
from api.services.unified_ingest_helper import compute_fingerprint, clean_text_for_postgres, get_chroma_collection

# ==========================================================
# ‚öôÔ∏è CONFIGURATION
# ==========================================================
LOG_DIR = os.path.join(os.getcwd(), "logs")
os.makedirs(LOG_DIR, exist_ok=True)
LOG_FILE = os.path.join(LOG_DIR, "intelligent_ingest.log")

logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger("intelligent_excel_ingest")

SUPPORTED_EXTENSIONS = [".xlsx", ".csv"]

# ==========================================================
# üß© HELPER FUNCTIONS
# ==========================================================
def read_file(file_path: str) -> pd.DataFrame:
    """Reads Excel or CSV file into a DataFrame."""
    _, ext = os.path.splitext(file_path)
    if ext.lower() == ".xlsx":
        df = pd.read_excel(file_path)
    elif ext.lower() == ".csv":
        df = pd.read_csv(file_path)
    else:
        raise ValueError(f"Unsupported file format: {ext}")
    df = df.dropna(how="all").fillna("")
    return df


def safe_str(value) -> str:
    """Convert any cell to safe string."""
    if pd.isna(value):
        return ""
    return str(value).strip()


def ensure_taxonomy(db, category_name: str, subcategory_name: str):
    """Ensures taxonomy and subcategory exist in DB, creates if missing."""
    category = (
        db.query(models.TaxonomyCategory)
        .filter(models.TaxonomyCategory.name.ilike(category_name))
        .first()
    )
    if not category:
        category = models.TaxonomyCategory(
            name=category_name, group="content", description="Auto-generated by LLM"
        )
        db.add(category)
        db.commit()

    subcategory = (
        db.query(models.TaxonomyCategory)
        .filter(models.TaxonomyCategory.name.ilike(subcategory_name))
        .first()
    )
    if not subcategory:
        subcategory = models.TaxonomyCategory(
            name=subcategory_name, group="content", description="Auto-generated subcategory"
        )
        db.add(subcategory)
        db.commit()

    return category, subcategory


def ensure_business(db, business_name: str, category_name: str):
    """Ensures a business exists or creates a new one."""
    if not business_name:
        business_name = "General Business"
    business = (
        db.query(models.Business)
        .filter(models.Business.name.ilike(business_name))
        .first()
    )
    if not business:
        business = models.Business(
            name=business_name,
            industry=category_name,
            description=f"Auto-created business under {category_name}",
        )
        db.add(business)
        db.commit()
    return business


# ==========================================================
# üöÄ MAIN INGEST FUNCTION
# ==========================================================
def ingest_excel_or_csv(file_path: str):
    """
    Main intelligent ingestion entry point.
    Reads the file, classifies each row via LLM, and updates DB + ChromaDB.
    """
    _, ext = os.path.splitext(file_path)
    if ext.lower() not in SUPPORTED_EXTENSIONS:
        raise ValueError("Unsupported file format.")

    logger.info(f"[Start] Intelligent ingestion started for {file_path}")
    df = read_file(file_path)
    logger.info(f"[FileRead] Loaded {len(df)} rows from {file_path}")

    chroma = get_chroma_collection()
    results = []

    with get_db_connection() as db:
        for i, row in df.iterrows():
            try:
                raw_text = " ".join(safe_str(x) for x in row.values if safe_str(x))
                if not raw_text.strip():
                    continue

                # üß† Clean & classify row
                cleaned_text = clean_text_for_postgres(raw_text)
                classification = classify_text_with_llm(cleaned_text)

                category = classification.get("category_level_1", "Uncategorized")
                subcategory = classification.get("category_level_2_sub", "General Business")
                business_name = classification.get("business_specific_name") or classification.get("business_concept_name")
                confidence = classification.get("extraction_confidence", 0.0)

                category, subcategory = ensure_taxonomy(db, category, subcategory)
                business = ensure_business(db, business_name, category.name)

                fingerprint = compute_fingerprint(cleaned_text)

                existing = (
                    db.query(models.Content)
                    .filter(models.Content.fingerprint == fingerprint)
                    .first()
                )
                if existing:
                    logger.info(f"[DuplicateSkip] Row {i+1} already exists.")
                    continue

                # üìù Store in contents
                content = models.Content(
                    business_id=business.id,
                    title=classification.get("title") or business.name,
                    content_type="row",
                    text=cleaned_text,
                    summary=classification.get("description", "")[:300],
                    category=category.name,
                    sub_category=subcategory.name,
                    tags={"auto": True},
                    content_metadata={
                        "source": "intelligent_excel_ingest",
                        "confidence": confidence,
                        "file_name": os.path.basename(file_path),
                    },
                    fingerprint=fingerprint,
                    confidence=confidence,
                )
                db.add(content)
                db.commit()
                db.refresh(content)

                # üîó Entity Link
                entity_link = models.EntityLink(
                    category_id=category.id,
                    subcategory_id=subcategory.id,
                    business_id=business.id,
                    entity_type="content",
                    entity_id=content.id,
                    fingerprint=fingerprint,
                    link_metadata={
                        "source": "intelligent_excel_ingest",
                        "file_name": os.path.basename(file_path),
                        "timestamp": str(datetime.utcnow()),
                    },
                )
                db.add(entity_link)
                db.commit()

                # üß† Add embedding to ChromaDB
                try:
                    chroma.add(
                        ids=[fingerprint],
                        documents=[cleaned_text],
                        metadatas=[{
                            "category": category.name,
                            "subcategory": subcategory.name,
                            "business": business.name,
                            "file": os.path.basename(file_path),
                            "confidence": confidence
                        }]
                    )
                except Exception as e:
                    logger.warning(f"[ChromaSkip] {e}")

                results.append({
                    "row": i + 1,
                    "business": business.name,
                    "category": category.name,
                    "subcategory": subcategory.name,
                    "confidence": confidence
                })

                logger.info(f"[RowSuccess] Row {i+1}: {business.name} | {category.name} > {subcategory.name}")

            except Exception as e:
                logger.error(f"[RowError] Row {i+1} failed: {e}")

    logger.info(f"[Complete] Intelligent ingestion finished for {file_path}")
    return results


# ==========================================================
# üß™ TEST EXECUTION
# ==========================================================
if __name__ == "__main__":
    test_file = os.path.join(os.getcwd(), "data", "uploads", "Catageroies_and_BusinessesV2.xlsx")
    if os.path.exists(test_file):
        output = ingest_excel_or_csv(test_file)
        print(json.dumps(output, indent=2))
        print("‚úÖ Intelligent ingestion completed successfully.")
    else:
        print(f"‚ö†Ô∏è Test file not found: {test_file}")
    